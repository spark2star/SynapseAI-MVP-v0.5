"""
Simple FastAPI app with basic authentication and STT testing.
"""

import asyncio
import json
import os
import threading
import queue
import time
from datetime import datetime, timezone
import numpy as np
from google.cloud import speech
from google.oauth2 import service_account
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Initialize Google Cloud Speech client with proper path
credentials_path = os.getenv("GCP_CREDENTIALS_PATH", "gcp-credentials.json")
print(f"Loading Google Cloud credentials from: {credentials_path}")

try:
credentials = service_account.Credentials.from_service_account_file(
        credentials_path,
    scopes=['https://www.googleapis.com/auth/cloud-platform']
)
speech_client = speech.SpeechClient(credentials=credentials)
    print("‚úÖ Google Cloud Speech client initialized successfully")
except Exception as e:
    print(f"‚ùå Failed to initialize Google Cloud Speech client: {e}")
    print("Will use mock transcription as fallback")
    speech_client = None

app = FastAPI(
    title="Intelligent EMR System",
    description="Healthcare Management System with AI Integration",
    version="1.0.0"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class LoginRequest(BaseModel):
    email: str
    password: str

class LoginResponse(BaseModel):
    access_token: str
    token_type: str
    user: dict

@app.get("/")
async def root():
    return {"message": "Intelligent EMR System is running!", "status": "healthy"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "EMR Backend"}

@app.get("/api/v1/health")
async def api_health_check():
    return {"status": "healthy", "service": "EMR API v1"}

@app.post("/api/v1/auth/login")
async def login(login_data: LoginRequest):
    """
    Temporary login endpoint for testing.
    Accepts demo credentials and returns mock tokens.
    """
    # Demo credentials
    demo_users = {
        "doctor@demo.com": {"password": "password123", "role": "doctor", "name": "Dr. Smith"},
        "admin@demo.com": {"password": "password123", "role": "admin", "name": "Admin User"},
        "reception@demo.com": {"password": "password123", "role": "receptionist", "name": "Reception"}
    }
    
    if login_data.email not in demo_users:
        raise HTTPException(status_code=401, detail="Invalid credentials")
    
    user_data = demo_users[login_data.email]
    if user_data["password"] != login_data.password:
        raise HTTPException(status_code=401, detail="Invalid credentials")
    
    return {
        "status": "success", 
        "data": {
            "access_token": "demo-jwt-token-12345",
            "refresh_token": "demo-refresh-token-67890",
            "token_type": "bearer",
            "user_id": f"demo-user-{user_data['role']}",
            "role": user_data["role"],
            "email": login_data.email,
            "name": user_data["name"]
        }
    }

@app.get("/api/v1/users/me")
async def get_current_user():
    """Mock current user endpoint."""
    return {
        "status": "success",
        "data": {
        "id": "demo-user-id",
        "email": "doctor@demo.com", 
        "role": "doctor",
        "name": "Dr. Smith"
        }
    }

@app.get("/api/v1/users/profile")
async def get_user_profile():
    """Mock user profile endpoint that frontend calls after login."""
    return {
        "status": "success",
        "data": {
            "id": "demo-user-id",
            "first_name": "Dr.",
            "last_name": "Smith",
            "email": "doctor@demo.com",
            "phone": "+1-555-0123",
            "specialization": "General Medicine",
            "license_number": "MD123456",
            "department": "Internal Medicine",
            "role": "doctor",
            "is_verified": True,
            "is_active": True,
            "created_at": "2024-01-01T00:00:00Z",
            "updated_at": "2024-01-01T00:00:00Z"
        }
    }

@app.get("/api/v1/auth/validate-token")
async def validate_token():
    """Mock token validation endpoint."""
    return {
        "status": "success",
        "data": {
            "valid": True,
            "user_id": "demo-user-id",
            "role": "doctor",
            "email": "doctor@demo.com"
        }
    }

@app.post("/api/v1/patients/create")
async def create_patient(patient_data: dict):
    """Mock patient creation endpoint."""
    return {
        "status": "success",
        "data": {
            "id": f"patient-{len(str(patient_data))}",
            "patient_id": f"PAT-{hash(str(patient_data)) % 10000:04d}",
            "first_name": patient_data.get("first_name"),
            "last_name": patient_data.get("last_name"),
            "email": patient_data.get("email"),
            "phone_primary": patient_data.get("phone_primary"),
            "created_at": "2024-01-01T00:00:00Z"
        },
        "message": "Patient registered successfully"
    }

@app.get("/api/v1/patients/list/")  
async def list_patients():
    """Mock patient list endpoint."""
    return {
        "status": "success",
        "data": {
            "patients": [
                {
                    "id": "patient-1",
                    "patient_id": "PAT-0001",
                    "full_name": "John Doe",
                    "age": 35,
                    "gender": "male",
                    "phone_primary": "+1-555-1234",
                    "last_visit": None,
                    "created_at": "2024-01-01T00:00:00Z"
                },
                {
                    "id": "patient-2", 
                    "patient_id": "PAT-0002",
                    "full_name": "Jane Smith",
                    "age": 28,
                    "gender": "female", 
                    "phone_primary": "+1-555-5678",
                    "last_visit": "2024-01-15T10:00:00Z",
                    "created_at": "2023-12-15T00:00:00Z"
                }
            ],
            "total_count": 2,
            "limit": 50,
            "offset": 0
        }
    }

@app.post("/api/v1/auth/mfa/setup")
async def setup_mfa():
    """Mock MFA setup endpoint."""
    import base64
    
    # Create a real QR code for demo
    try:
        import qrcode
        import io
        
        # Generate a mock QR code
        qr = qrcode.QRCode(version=1, box_size=10, border=5)
        qr.add_data("otpauth://totp/EMR-System:doctor@demo.com?secret=JBSWY3DPEHPK3PXP&issuer=EMR-System")
        qr.make(fit=True)
        
        img = qr.make_image(fill_color="black", back_color="white")
        img_buffer = io.BytesIO()
        img.save(img_buffer, format='PNG')
        img_buffer.seek(0)
        qr_code_base64 = base64.b64encode(img_buffer.getvalue()).decode()
        qr_data_url = f"data:image/png;base64,{qr_code_base64}"
    except ImportError:
        # Fallback if qrcode not available
        qr_data_url = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg=="
    
    return {
        "status": "success",
        "data": {
            "qr_code": qr_data_url,
            "secret": "JBSWY3DPEHPK3PXP",
            "backup_codes": [
                "BACKUP01", "BACKUP02", "BACKUP03", "BACKUP04", "BACKUP05",
                "BACKUP06", "BACKUP07", "BACKUP08", "BACKUP09", "BACKUP10"
            ],
            "instructions": "Scan the QR code with your authenticator app (Google Authenticator, Authy, etc.) and verify with a 6-digit code."
        }
    }

@app.post("/api/v1/auth/mfa/verify-setup")
async def verify_mfa_setup(request_data: dict):
    """Mock MFA verification endpoint."""
    return {
        "status": "success", 
        "data": {
            "mfa_enabled": True,
            "message": "MFA has been successfully enabled for your account"
        }
    }

@app.post("/api/v1/auth/mfa/disable")
async def disable_mfa():
    """Mock MFA disable endpoint."""
    return {
        "status": "success",
        "data": {
            "mfa_disabled": True,
            "message": "MFA has been disabled for your account"
        }
    }

@app.get("/api/v1/patients/{patient_id}")
async def get_patient_details(patient_id: str):
    """Mock patient details endpoint."""
    if patient_id == "patient-1":
        return {
            "status": "success",
            "data": {
                "id": "patient-1",
                "patient_id": "PAT-0001",
                "full_name": "John Doe",
                "age": 35,
                "gender": "male",
                "phone_primary": "+1-555-1234",
                "email": "john.doe@email.com",
                "address": "123 Main St, City, State 12345",
                "emergency_contact": "Mary Doe (+1-555-9999)",
                "blood_group": "O+",
                "allergies": "Penicillin, Peanuts",
                "medical_history": "Hypertension, Diabetes Type 2",
                "created_at": "2024-01-01T00:00:00Z",
                "last_visit": None
            }
        }
    else:
        return {
            "status": "success", 
            "data": {
                "id": "patient-2",
                "patient_id": "PAT-0002",
                "full_name": "Jane Smith",
                "age": 28,
                "gender": "female",
                "phone_primary": "+1-555-5678",
                "email": "jane.smith@email.com",
                "address": "456 Oak Ave, City, State 67890",
                "emergency_contact": "Bob Smith (+1-555-8888)",
                "blood_group": "A+",
                "allergies": "None known",
                "medical_history": "Asthma",
                "created_at": "2023-12-15T00:00:00Z",
                "last_visit": "2024-01-15T10:00:00Z"
            }
        }

@app.post("/api/v1/consultation/start")
async def start_consultation_session(session_data: dict):
    """Mock consultation session start endpoint."""
    return {
        "status": "success",
        "data": {
            "session_id": "CS-2024-NEW",
            "patient_id": session_data.get("patient_id"),
            "doctor_id": session_data.get("doctor_id"), 
            "status": "in_progress",
            "started_at": "2024-01-01T00:00:00Z",
            "chief_complaint": session_data.get("chief_complaint"),
            "recording_url": "ws://localhost:8000/ws/consultation/CS-2024-NEW"
        }
    }

@app.post("/api/v1/consultation/{session_id}/stop")
async def stop_consultation_session(session_id: str):
    """Mock consultation session stop endpoint."""
    return {
        "status": "success",
        "data": {
            "session_id": session_id,
            "status": "completed",
            "ended_at": "2024-01-01T00:30:00Z",
            "duration_minutes": 30,
            "transcription_status": "completed",
            "has_recording": True
        }
    }

@app.post("/api/v1/reports/generate")
async def generate_medical_report_mock(request_data: dict):
    """Mock AI-powered medical report generation."""
    return {
        "status": "success",
        "data": {
            "session_id": request_data.get("session_id", "CS-2024-NEW"),
            "report": {
                "report_type": request_data.get("report_type", "consultation"),
                "content": "AI-Generated Medical Report\n\nCHIEF COMPLAINT:\nRoutine checkup and health assessment as discussed during consultation.\n\nHISTORY OF PRESENT ILLNESS:\nPatient reports feeling generally well with no acute concerns. Routine follow-up visit for ongoing health maintenance.\n\nASSESSMENT:\n- Overall health status appears stable\n- Vital signs within normal ranges\n- No acute medical issues identified\n\nPLAN:\n- Continue current health maintenance routine\n- Follow-up in 6 months or as needed\n- Patient education provided regarding preventive care\n\nCLINICAL INSIGHTS:\n- Patient demonstrates good health awareness\n- Compliance with recommended care protocols\n- Low risk profile for acute medical events",
                "sections": {
                    "CHIEF COMPLAINT": "Routine checkup and health assessment",
                    "ASSESSMENT": "Overall health status appears stable",
                    "PLAN": "Continue current health maintenance routine"
                },
                "confidence": 0.95,
                "ai_generated": True,
                "model": "gemini-2.5-flash"
            },
            "insights": {
                "key_findings": ["Patient in good health", "No acute concerns"],
                "recommendations": ["Continue preventive care", "Regular follow-ups"],
                "confidence": 0.92
            },
            "metadata": {
                "generated_at": "2024-01-01T00:30:00Z",
                "model_used": "gemini-2.5-flash",
                "confidence": 0.95,
                "report_type": request_data.get("report_type", "consultation")
            }
        }
    }

@app.post("/api/v1/reports/insights")
async def generate_clinical_insights_mock(request_data: dict):
    """Mock AI-powered clinical insights generation."""
    return {
        "status": "success",
        "data": {
            "insights": {
                "key_clinical_findings": [
                    "Patient appears well-oriented and cooperative",
                    "No signs of acute distress observed",
                    "Communication clear and appropriate"
                ],
                "differential_diagnosis": [
                    "Normal health status - no pathology indicated",
                    "Routine health maintenance encounter"
                ],
                "treatment_recommendations": [
                    "Continue current lifestyle patterns",
                    "Maintain regular exercise routine",
                    "Follow balanced nutrition guidelines"
                ],
                "follow_up_priorities": [
                    "Schedule routine follow-up in 6 months",
                    "Monitor for any new symptoms",
                    "Continue preventive care measures"
                ],
                "confidence": 0.94
            },
            "metadata": {
                "generated_at": "2024-01-01T00:30:00Z",
                "model_used": "gemini-2.5-flash",
                "analysis_type": "clinical_insights"
            }
        }
    }

@app.get("/api/v1/reports/health")
async def reports_health_check():
    """Mock AI services health check."""
    return {
        "status": "success",
        "data": {
            "gemini_service": "available",
            "vertex_ai": "connected",
            "timestamp": "2024-01-01T00:00:00Z",
            "version": "1.0.0"
        }
    }

@app.post("/api/v1/reports/live-insights")
async def generate_live_insights(request_data: dict):
    """
    Generate live AI insights during active consultation sessions.
    Optimized for real-time partial analysis with mental health focus.
    """
    try:
        # Extract request data
        transcription_text = request_data.get("transcription_text", "")
        patient_id = request_data.get("patient_id")
        session_id = request_data.get("session_id")
        is_partial = request_data.get("is_partial", True)
        
        # Validate minimum text length
        if len(transcription_text.strip()) < 20:
            return {
                "status": "success",
                "data": {
                    "insights": {
                        "key_clinical_findings": [],
                        "treatment_recommendations": [],
                        "confidence": 0.0
                    },
                    "message": "Insufficient text for analysis"
                }
            }
        
        # Generate mental health focused live insights based on transcription
        # This analyzes the real transcription text for mental health indicators
        
        # Key terms analysis for mental health
        mental_health_indicators = {
            "anxiety": ["anxious", "anxiety", "worry", "nervous", "panic", "restless", "‡§ö‡§ø‡§Ç‡§§‡§æ", "‡§ò‡§¨‡§∞‡§æ‡§ü"],
            "depression": ["sad", "depression", "hopeless", "empty", "tired", "worthless", "‡§â‡§¶‡§æ‡§∏", "‡§®‡§ø‡§∞‡§æ‡§∂"],
            "sleep": ["sleep", "insomnia", "tired", "rest", "awake", "‡§ù‡•ã‡§™", "‡§•‡§ï‡§µ‡§æ"],
            "mood": ["mood", "happy", "sad", "angry", "irritable", "‡§Æ‡•Ç‡§°", "‡§∞‡§æ‡§ó"],
            "stress": ["stress", "pressure", "overwhelmed", "burden", "‡§§‡§£‡§æ‡§µ", "‡§¶‡§¨‡§æ‡§µ"],
            "family": ["family", "relationship", "partner", "‡§ï‡•Å‡§ü‡•Å‡§Ç‡§¨", "‡§®‡§æ‡§§‡•á‡§∏‡§Ç‡§¨‡§Ç‡§ß"],
            "work": ["work", "job", "office", "career", "‡§ï‡§æ‡§Æ", "‡§®‡•ã‡§ï‡§∞‡•Ä"]
        }
        
        findings = []
        recommendations = []
        confidence = 0.0
        
        text_lower = transcription_text.lower()
        
        # Analyze for key indicators
        for category, keywords in mental_health_indicators.items():
            if any(keyword in text_lower for keyword in keywords):
                if category == "anxiety":
                    findings.append("Patient reports anxiety symptoms")
                    recommendations.append("Consider anxiety management techniques and breathing exercises")
                elif category == "depression":
                    findings.append("Indicators of depressive symptoms noted")
                    recommendations.append("Monitor mood patterns and consider cognitive behavioral therapy")
                elif category == "sleep":
                    findings.append("Sleep-related concerns mentioned")
                    recommendations.append("Evaluate sleep hygiene and consider sleep study if persistent")
                elif category == "stress":
                    findings.append("Stress factors identified")
                    recommendations.append("Discuss stress management strategies and coping mechanisms")
                elif category == "family":
                    findings.append("Family or relationship concerns mentioned")
                    recommendations.append("Consider family therapy or relationship counseling")
                elif category == "work":
                    findings.append("Work-related stress or concerns noted")
                    recommendations.append("Discuss work-life balance and workplace stress management")
                
                confidence += 0.12
        
        # General mental health recommendations based on content
        if findings:
            recommendations.append("Continue regular monitoring and follow-up sessions")
            if len(transcription_text.split()) > 50:
                recommendations.append("Document detailed progress notes for comprehensive care")
        
        # Limit confidence to realistic levels for live analysis
        confidence = min(confidence, 0.85)
        
        return {
            "status": "success",
            "data": {
                "insights": {
                    "key_clinical_findings": findings[:4],  # Limit to top 4
                    "treatment_recommendations": recommendations[:4],  # Limit to top 4
                    "confidence": round(confidence, 2)
                },
                "metadata": {
                    "generated_at": datetime.now(timezone.utc).isoformat(),
                    "model_used": "live-analysis-engine-v1",
                    "analysis_type": "live_insights",
                    "is_partial": is_partial,
                    "session_id": session_id,
                    "text_length": len(transcription_text),
                    "languages_detected": ["en", "mr", "hi"]
                }
            }
        }
        
    except Exception as e:
        # Don't raise errors for live insights to avoid disrupting the frontend
        print(f"Live insights error: {str(e)}")
        return {
            "status": "success",
            "data": {
                "insights": {
                    "key_clinical_findings": [],
                    "treatment_recommendations": [],
                    "confidence": 0.0
                },
                "message": "Analysis temporarily unavailable"
            }
        }

@app.get("/api/v1/consultation/test")
async def test_stt_service():
    """
    Test Google Cloud Speech-to-Text service availability and configuration.
    """
    try:
        # Test basic client initialization
        project_id = "synapse-product-1"
        
        # Test actual speech client initialization (if available)
        if speech_client is None:
            raise Exception("Google Cloud Speech client not initialized")
        test_client = speech_client
        
        # Create a simple recognition config for testing
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="en-US",
        )
        
        return {
            "status": "success", 
            "data": {
                "stt_service": "available",
                "project_id": project_id,
                "supported_languages": ["en-IN", "mr-IN", "hi-IN"],
                "mental_health_optimized": True,
                "credentials_valid": True,
                "client_initialized": True,
                "config": {
                    "model": "latest_long",
                    "sample_rate": 48000,
                    "encoding": "WEBM_OPUS",
                    "enable_word_confidence": True,
                    "enable_word_time_offsets": True,
                    "streaming_support": True
                }
            },
            "message": "Google Cloud Speech-to-Text service is ready for real-time mental health consultations"
        }
        
    except Exception as e:
        return {
            "status": "error",
            "message": f"STT service test failed: {str(e)}",
            "data": {
                "stt_service": "unavailable",
                "error_details": str(e),
                "credentials_path": "gcp-credentials.json",
                "project_id": project_id
            }
        }

@app.post("/api/v1/consultation/start")
async def start_consultation_session(session_data: dict):
    """Mock consultation session start endpoint with STT integration."""
    try:
        session_id = f"CS-{datetime.now().strftime('%Y%m%d')}-{hash(str(session_data)) % 10000:04d}"
        
        return {
            "status": "success",
            "data": {
                "session_id": session_id,
                "patient_name": session_data.get("patient_name", "Test Patient"),
                "started_at": datetime.now(timezone.utc).isoformat(),
                "stt_session": {
                    "enabled": True,
                    "languages": ["mr-IN", "en-IN", "hi-IN"],
                    "model": "latest_long",
                    "mental_health_optimized": True
                },
                "websocket_url": f"ws://localhost:8000/ws/consultation/{session_id}"
            },
            "message": "Consultation session started with STT enabled"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to start consultation: {str(e)}")

@app.post("/api/v1/consultation/{session_id}/stop")
async def stop_consultation_session(session_id: str):
    """Mock consultation session stop endpoint."""
    return {
        "status": "success",
        "data": {
            "session_id": session_id,
            "ended_at": datetime.now(timezone.utc).isoformat(),
            "duration_minutes": 15,
            "stt_summary": {
                "total_words": 450,
                "languages_detected": ["english", "marathi"],
                "confidence_average": 0.94
            }
        },
        "message": "Consultation session completed successfully"
    }

@app.websocket("/ws/consultation/{session_id}")
async def websocket_consultation_endpoint(websocket: WebSocket, session_id: str):
    """
    Real-time WebSocket endpoint for consultation audio streaming and transcription.
    Uses Google Cloud Speech-to-Text with mental health optimization.
    """
    await websocket.accept()
    print(f"WebSocket connected for session: {session_id}")
    
    # Initialize variables for cleanup
    speech_client = None
    stop_event = None
    streaming_thread = None
    
    try:
        # Send welcome message
        await websocket.send_json({
            "type": "connected", 
            "message": "Connected to SynapseAI Real-time Speech Recognition",
            "session_id": session_id,
            "stt_config": {
                "languages": ["mr-IN", "en-IN", "hi-IN"],
                "model": "latest_long",
                "mental_health_optimized": True
            }
        })
        
        # Use the globally initialized speech client
        import sys
        current_module = sys.modules[__name__]
        module_speech_client = getattr(current_module, 'speech_client', None)
        print(f"üîç Checking module speech_client: {module_speech_client is not None}")
        print(f"üîç Local speech_client: {speech_client is not None}")
        if module_speech_client is None:
            raise Exception("Google Cloud Speech client not initialized - check credentials")
        
        # Mental health specific terms for enhanced recognition
        mental_health_phrases = [
            "anxiety", "depression", "stress", "panic", "therapy", "counseling", "medication",
            "mood", "sleep", "insomnia", "worry", "fear", "trauma", "PTSD", "bipolar",
            "mindfulness", "meditation", "cognitive behavioral therapy", "CBT", "psychotherapy",
            "mental health", "psychiatric", "antidepressant", "anxiolytic", "mood stabilizer",
            "‡§ö‡§ø‡§Ç‡§§‡§æ", "‡§§‡§£‡§æ‡§µ", "‡§â‡§¶‡§æ‡§∏‡•Ä‡§®‡§§‡§æ", "‡§Æ‡§æ‡§®‡§∏‡§ø‡§ï ‡§Ü‡§∞‡•ã‡§ó‡•ç‡§Ø", "‡§•‡•á‡§∞‡§™‡•Ä", "‡§î‡§∑‡§ß",
            "‡§ù‡•ã‡§™", "‡§ò‡§¨‡§∞‡§æ‡§ü", "‡§Æ‡•Ç‡§°", "‡§Æ‡§®", "‡§≠‡§æ‡§µ‡§®‡§æ", "‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ"
        ]
        
        # Configure streaming recognition (simplified for debugging)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="en-US",  # Start with basic English for testing
            model="default",  # Use default model to avoid potential issues
            enable_automatic_punctuation=False,  # Disable for simplicity
            enable_word_confidence=False,  # Disable for simplicity
            # Remove speech contexts for now to simplify
        )
        
        print(f"üîß Using simplified STT config: encoding=LINEAR16, rate=16000, lang=en-US, model=default")
        import sys
        sys.stdout.flush()
        
        streaming_config = speech.StreamingRecognitionConfig(
            config=config,
            interim_results=True,
            single_utterance=False
        )
        
        print(f"Google Cloud Speech-to-Text initialized for session {session_id}")
        
        # Send confirmation of STT readiness
        await websocket.send_json({
            "type": "stt_ready",
            "message": "Google Cloud Speech-to-Text ready for mental health consultation",
            "timestamp": datetime.now(timezone.utc).isoformat()
        })
        
        # Streaming recognition setup using a background thread and a queue
        audio_queue: queue.Queue[bytes] = queue.Queue(maxsize=200)
        stop_event = threading.Event()
        
        loop = asyncio.get_running_loop()
        
        def requests_generator():
            # Generate audio requests only (config passed separately)
            print(f"üéØ Starting audio request generator...")
            print(f"üîç Queue initial size: {audio_queue.qsize()}")
            import sys
            sys.stdout.flush()
            
            silence_chunk = b"\x00\x00" * 800  # 50ms of 16kHz 16-bit PCM
            requests_sent = 0
            last_real_audio_time = time.time()
            
            # CRITICAL: Wait for real audio before starting stream
            print(f"‚è≥ Waiting for real audio before starting stream...")
            sys.stdout.flush()
            
            # Wait up to 10 seconds for first real audio chunk
            first_audio_received = False
            wait_start = time.time()
            while not first_audio_received and not stop_event.is_set():
                if time.time() - wait_start > 10.0:
                    print(f"‚ö†Ô∏è Timeout waiting for audio, starting with silence")
                    break
                try:
                    first_chunk = audio_queue.get(timeout=0.5)
                    if first_chunk and len(first_chunk) > 0:
                        print(f"üéâ First real audio received: {len(first_chunk)} bytes!")
                        sys.stdout.flush()
                        # Send the first real audio chunk
                        yield speech.StreamingRecognizeRequest(audio_content=first_chunk)
                        requests_sent += 1
                        last_real_audio_time = time.time()
                        first_audio_received = True
                        print(f"‚úÖ First real audio sent (#{requests_sent})")
                        sys.stdout.flush()
                except queue.Empty:
                    continue
            
            # If no real audio received, send initial silence
            if not first_audio_received:
                initial_request = speech.StreamingRecognizeRequest(audio_content=silence_chunk)
                yield initial_request
                requests_sent += 1
                print(f"‚úÖ Initial silence sent (#{requests_sent})")
                sys.stdout.flush()
            
            # Simple continuous streaming - prioritize real audio, minimal silence
            while not stop_event.is_set():
                try:
                    # Get audio with longer timeout to avoid spam
                    chunk: bytes = audio_queue.get(timeout=0.2)
                    if chunk and len(chunk) > 0:
                        # Send real audio immediately
                        request = speech.StreamingRecognizeRequest(audio_content=chunk)
                        yield request
                        requests_sent += 1
                        last_real_audio_time = time.time()
                        queue_remaining = audio_queue.qsize()
                        print(f"üì§ Streaming audio to Google: {len(chunk)} bytes (request #{requests_sent}), queue: {queue_remaining}")
                        sys.stdout.flush()
                except queue.Empty:
                    # Send minimal silence only when necessary
                    current_time = time.time()
                    time_since_audio = current_time - last_real_audio_time
                    
                    if time_since_audio < 3.0:  # Only send silence for 3 seconds after last audio
                        request = speech.StreamingRecognizeRequest(audio_content=silence_chunk)
                        yield request
                        requests_sent += 1
                        if requests_sent % 30 == 0:  # Less spam
                            print(f"üîá Silence keepalive (request #{requests_sent})")
                            sys.stdout.flush()
                    
                    time.sleep(0.1)  # Brief delay
            
            print(f"üèÅ Audio request generator ended. Total requests sent: {requests_sent}")
        
        def run_streaming():
            print(f"üöÄ SIMPLE STT Stream for {session_id}")
            import sys
            sys.stdout.flush()
            
            # Get speech client
            current_module = sys.modules[__name__]
            module_speech_client = getattr(current_module, 'speech_client', None)
            if module_speech_client is None:
                print("‚ùå No speech client available")
                return
            
            # WORKING PATTERN: Based on successful implementation
            def request_generator():
                """Generate requests: streaming_config first, then audio chunks."""
                print(f"üéØ Request generator started")
                sys.stdout.flush()
                
                # CRITICAL: Send streaming config as FIRST request (exactly like working code)
                yield speech.StreamingRecognizeRequest(streaming_config=streaming_config)
                print(f"‚úÖ Streaming config sent as first request")
                sys.stdout.flush()
                
                # Then send audio chunks
                requests_sent = 1  # Already sent config
                silence = b"\x00\x00" * 800  # 50ms silence
                
                while not stop_event.is_set():
                    try:
                        # Get audio chunk
                        audio_data = audio_queue.get(timeout=0.1)
                        if audio_data and len(audio_data) > 0:
                            yield speech.StreamingRecognizeRequest(audio_content=audio_data)
                            requests_sent += 1
                            if requests_sent % 20 == 0:
                                print(f"üì§ Audio chunk sent: {len(audio_data)} bytes (#{requests_sent})")
                                sys.stdout.flush()
                    except queue.Empty:
                        # Send silence to keep stream alive
                        yield speech.StreamingRecognizeRequest(audio_content=silence)
                        requests_sent += 1
                        time.sleep(0.05)
                
                print(f"üèÅ Request generator ended: {requests_sent} total")
                sys.stdout.flush()
            
            try:
                print(f"üìû Calling streaming_recognize...")
                sys.stdout.flush()
                
                # WORKING PATTERN: Use request_generator() only (like successful implementation)
                responses = module_speech_client.streaming_recognize(
                    requests=request_generator()
                )
                
                print(f"üì° Processing STT responses...")
                sys.stdout.flush()
                
                # Process responses
                for response in responses:
                    if stop_event.is_set():
                        break
                    
                    if hasattr(response, 'error') and response.error:
                        error_code = getattr(response.error, 'code', 'no_code')
                        error_message = getattr(response.error, 'message', 'no_message') 
                        error_details = getattr(response.error, 'details', 'no_details')
                        print(f"‚ùå FULL STT ERROR: code={error_code}, message='{error_message}', details='{error_details}'")
                        print(f"üîç Full error object: {response.error}")
                        sys.stdout.flush()
                        continue
                    
                    if not response.results:
                        continue
                        
                    result = response.results[0]
                    if not result.alternatives:
                        continue
                        
                                        transcript = result.alternatives[0].transcript.strip()
                    is_final = getattr(result, 'is_final', False)
                    confidence = getattr(result.alternatives[0], 'confidence', 0.0)
                    
                    if transcript:  # Only send non-empty transcripts
                        print(f"‚úÖ {'FINAL' if is_final else 'interim'}: '{transcript}'")
                        sys.stdout.flush()
                        
                        # Send to frontend
                        asyncio.run_coroutine_threadsafe(
                            websocket.send_json({
                                                "type": "transcription",
                                                "data": {
                                    "type": "final" if is_final else "interim",
                                                    "transcript": transcript,
                                                    "confidence": round(confidence, 2),
                                                    "timestamp": datetime.now(timezone.utc).isoformat(),
                                    "source": "google_streaming",
                                    "language_detected": config.language_code,
                                                    "mental_health_optimized": True
                                                }
                            }),
                            loop,
                        )
                
                print(f"üèÅ STT completed for session {session_id}")
                
            except Exception as e:
                print(f"‚ùå STT failed: {type(e).__name__}: {str(e)}")
                import traceback
                traceback.print_exc()
                sys.stdout.flush()
        
        # Start STT streaming in background thread
        def run_streaming_wrapper():
            print(f"üöÄ STT THREAD STARTING for session {session_id}")
            import sys
            sys.stdout.flush()  # Force immediate output
            try:
                run_streaming()
            except Exception as thread_error:
                print(f"üí• CRITICAL STT THREAD ERROR: {thread_error}")
                import traceback
                traceback.print_exc()
                sys.stdout.flush()
        
        streaming_thread = threading.Thread(target=run_streaming_wrapper, daemon=True)
        streaming_thread.start()
        print(f"üé§ STT thread started for session {session_id}")
        import sys
        sys.stdout.flush()  # Force immediate output
        
        # Main WebSocket loop
        while True:
            try:
                # Wait for data from frontend
                data = await asyncio.wait_for(websocket.receive(), timeout=10.0)
                
                if "bytes" in data:
                    # Handle audio data (binary PCM 16-bit little endian)
                    audio_data = data["bytes"]
                    if len(audio_data) > 0:
                        # Push to streaming queue
                        try:
                            audio_queue.put_nowait(audio_data)
                            queue_size = audio_queue.qsize()
                            print(f"Received audio chunk: {len(audio_data)} bytes, queue size: {queue_size}")
                            import sys
                            sys.stdout.flush()
                        except queue.Full:
                            # Drop if queue is full to avoid backpressure
                            print(f"‚ö†Ô∏è Audio queue full, dropping {len(audio_data)} bytes")
                            pass
                
                elif "text" in data:
                    # Handle control messages
                    try:
                        message = json.loads(data["text"])
                        message_type = message.get("type")
                        
                        if message_type == "stop_recording":
                            stop_event.set()
                            break
                        elif message_type == "pause_recording":
                            print(f"Recording paused for session {session_id}")
                            await websocket.send_json({
                                "type": "recording_paused",
                                "timestamp": datetime.now(timezone.utc).isoformat()
                            })
                        elif message_type == "resume_recording":
                            print(f"Recording resumed for session {session_id}")
                        await websocket.send_json({
                                "type": "recording_resumed",
                            "timestamp": datetime.now(timezone.utc).isoformat()
                        })
                        elif message_type == "ping":
                            await websocket.send_json({
                                "type": "pong",
                                "timestamp": datetime.now(timezone.utc).isoformat()
                            })
                    except json.JSONDecodeError:
                        print(f"Invalid JSON message received for session {session_id}")
                    
            except asyncio.TimeoutError:
                # Send heartbeat to keep connection alive
                await websocket.send_json({
                    "type": "heartbeat",
                    "timestamp": datetime.now(timezone.utc).isoformat()
                })
                continue
                
    except WebSocketDisconnect:
        print(f"WebSocket disconnected for session: {session_id}")
    except Exception as e:
        print(f"WebSocket error for session {session_id}: {str(e)}")
        try:
            await websocket.send_json({
                "type": "error",
                "message": f"Connection error: {str(e)}"
            })
        except:
            pass
    finally:
        # Cleanup
        if stop_event:
            stop_event.set()
        try:
            if streaming_thread and streaming_thread.is_alive():
                streaming_thread.join(timeout=1.5)
        except Exception:
            pass
        print(f"WebSocket connection closed for session: {session_id}")